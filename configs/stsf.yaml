# Single-Task Single-Feature
experiment_name: wm_stsf
scenario: STSF

# Data
use_real_stimuli: true
n_values: [2]
task_features: ["category"]
sequence_length: 6  # Paper uses 6 (not 10)
batch_size: 16
num_train: 2000  # More sequences for better learning
num_val: 200
num_test: 100
num_workers: 2
match_probability: 0.5  # Balance match vs non_match for t>=n

# Model
hidden_size: 256  # Paper uses 256 for GRU/LSTM (not 512)
rnn_type: "gru"   # rnn|gru|lstm
num_layers: 5
dropout: 0.2
pretrained_backbone: true
freeze_backbone: true
classifier_layers: [64,16]

# Optim
epochs: 16  # 14000 sequences / 16 batch = 875 batches/epoch * 16 = 14k iterations
lr: 0.0003  # Paper uses 3e-5
weight_decay: 0.00001
milestones: [10, 13]  # Adjust for longer training
gamma: 0.1
grad_clip: 1.0
label_smoothing: 0.1

# Validation
save_hidden: true
save_visualizations: true  # Save sequence visualization images during training
mask_trivial_steps: true  # Train/evaluate metrics on t>=n only
